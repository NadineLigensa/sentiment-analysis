{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/sulu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/sulu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (‚Ä¶)okenizer_config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 618/618 [00:00<00:00, 46.8kB/s]\n",
      "Downloading (‚Ä¶)tencepiece.bpe.model: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.07M/5.07M [00:00<00:00, 6.73MB/s]\n",
      "Downloading (‚Ä¶)/main/tokenizer.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9.10M/9.10M [00:01<00:00, 6.31MB/s]\n",
      "Downloading (‚Ä¶)cial_tokens_map.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:00<00:00, 45.6kB/s]\n",
      "Downloading (‚Ä¶)lve/main/config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 992/992 [00:00<00:00, 316kB/s]\n",
      "Downloading pytorch_model.bin: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.11G/1.11G [02:49<00:00, 6.55MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"citizenlab/twitter-xlm-roberta-base-sentiment-finetunned\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"citizenlab/twitter-xlm-roberta-base-sentiment-finetunned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(\"citizenlab/twitter-xlm-roberta-base-sentiment-finetunned\")\n",
    "model.save_pretrained(\"citizenlab/twitter-xlm-roberta-base-sentiment-finetunned\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('citizenlab/twitter-xlm-roberta-base-sentiment-finetunned/tokenizer_config.json',\n",
       " 'citizenlab/twitter-xlm-roberta-base-sentiment-finetunned/special_tokens_map.json',\n",
       " 'citizenlab/twitter-xlm-roberta-base-sentiment-finetunned/sentencepiece.bpe.model',\n",
       " 'citizenlab/twitter-xlm-roberta-base-sentiment-finetunned/added_tokens.json',\n",
       " 'citizenlab/twitter-xlm-roberta-base-sentiment-finetunned/tokenizer.json')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"citizenlab/twitter-xlm-roberta-base-sentiment-finetunned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = text.split()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    text = ' '.join(lemmatized_words)\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Positive 0.8976\n",
      "2) Neutral 0.1007\n",
      "3) Negative 0.0017\n"
     ]
    }
   ],
   "source": [
    "text = \"Good night üòä\"\n",
    "text = preprocess(text)\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "\n",
    "\n",
    "# Print labels and scores\n",
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "for i in range(scores.shape[0]):\n",
    "    l = config.id2label[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model on the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genauigkeit: 62.10%\n"
     ]
    }
   ],
   "source": [
    "# Laden Sie Ihren CSV-Datensatz\n",
    "csv_file = \"../../data/val_data.csv\"  # Ersetzen Sie durch den Pfad zu Ihrer CSV-Datei\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Leere Listen zum Speichern der vorhergesagten Sentiments und der tats√§chlichen Labels\n",
    "predicted_sentiments = []\n",
    "actual_labels = []\n",
    "\n",
    "count = 0\n",
    "# Durchlaufen Sie jeden Eintrag im DataFrame und wenden Sie das Modell an\n",
    "for index, row in df.iterrows():\n",
    "    text = row['text']\n",
    "    text = preprocess(text)  # Stellen Sie sicher, dass Sie Ihre Preprocessing-Funktion hier verwenden\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    softmax_scores = softmax(scores)\n",
    "\n",
    "    # Extrahieren Sie das vorhergesagte Sentiment\n",
    "    predicted_label_id = np.argmax(softmax_scores)\n",
    "    #predicted_sentiment = model.config.id2label[predicted_label_id]\n",
    "\n",
    "    # Speichern Sie das vorhergesagte Sentiment und das tats√§chliche Label\n",
    "    predicted_sentiments.append(predicted_label_id)\n",
    "    actual_labels.append(row['label'])\n",
    "\n",
    "# F√ºgen Sie die vorhergesagten Sentiments und die tats√§chlichen Labels als neue Spalten zum DataFrame hinzu\n",
    "df['predicted_sentiment'] = predicted_sentiments\n",
    "\n",
    "# Vergleichen Sie die vorhergesagten Sentiments mit den tats√§chlichen Labels\n",
    "correct_predictions = (df['predicted_sentiment'] == df['label']).sum()\n",
    "total_predictions = len(df)\n",
    "\n",
    "# Berechnen Sie die Genauigkeit (Accuracy) der Vorhersagen\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "# Drucken Sie die Genauigkeit\n",
    "print(f\"Genauigkeit: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genauigkeit: 63.96%\n"
     ]
    }
   ],
   "source": [
    "# Laden Sie Ihren CSV-Datensatz\n",
    "csv_file = \"../../data/test_data.csv\"  # Ersetzen Sie durch den Pfad zu Ihrer CSV-Datei\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Leere Listen zum Speichern der vorhergesagten Sentiments und der tats√§chlichen Labels\n",
    "predicted_sentiments = []\n",
    "actual_labels = []\n",
    "\n",
    "count = 0\n",
    "# Durchlaufen Sie jeden Eintrag im DataFrame und wenden Sie das Modell an\n",
    "for index, row in df.iterrows():\n",
    "    text = row['text']\n",
    "    text = preprocess(text)  # Stellen Sie sicher, dass Sie Ihre Preprocessing-Funktion hier verwenden\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    softmax_scores = softmax(scores)\n",
    "\n",
    "    # Extrahieren Sie das vorhergesagte Sentiment\n",
    "    predicted_label_id = np.argmax(softmax_scores)\n",
    "    #predicted_sentiment = model.config.id2label[predicted_label_id]\n",
    "\n",
    "    # Speichern Sie das vorhergesagte Sentiment und das tats√§chliche Label\n",
    "    predicted_sentiments.append(predicted_label_id)\n",
    "    actual_labels.append(row['label'])\n",
    "\n",
    "# F√ºgen Sie die vorhergesagten Sentiments und die tats√§chlichen Labels als neue Spalten zum DataFrame hinzu\n",
    "df['predicted_sentiment'] = predicted_sentiments\n",
    "\n",
    "# Vergleichen Sie die vorhergesagten Sentiments mit den tats√§chlichen Labels\n",
    "correct_predictions = (df['predicted_sentiment'] == df['label']).sum()\n",
    "total_predictions = len(df)\n",
    "\n",
    "# Berechnen Sie die Genauigkeit (Accuracy) der Vorhersagen\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "# Drucken Sie die Genauigkeit\n",
    "print(f\"Genauigkeit: {accuracy:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe54a73c18050b6d50975a0cc591f481f480ecb39df2bfc4b76ac59282f6b0b9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
