{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/sulu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/sulu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and save the model from the internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-16 12:02:03.997845: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "# PT\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "model.save_pretrained(MODEL)\n",
    "tokenizer.save_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess text (username and link placeholders)\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = text.split()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    text = ' '.join(lemmatized_words)\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Covid cases are increasing fast!\"\n",
    "text = preprocess(text)\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "# # TF\n",
    "# model = TFAutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "# model.save_pretrained(MODEL)\n",
    "# text = \"Covid cases are increasing fast!\"\n",
    "# encoded_input = tokenizer(text, return_tensors='tf')\n",
    "# output = model(encoded_input)\n",
    "# scores = output[0][0].numpy()\n",
    "# scores = softmax(scores)\n",
    "# Print labels and scores\n",
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "for i in range(scores.shape[0]):\n",
    "    l = config.id2label[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model on validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genauigkeit: 76.70%\n"
     ]
    }
   ],
   "source": [
    "# Laden Sie Ihren CSV-Datensatz\n",
    "csv_file = \"../../data/val_data.csv\"  # Ersetzen Sie durch den Pfad zu Ihrer CSV-Datei\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Leere Listen zum Speichern der vorhergesagten Sentiments und der tatsächlichen Labels\n",
    "predicted_sentiments = []\n",
    "actual_labels = []\n",
    "\n",
    "# Durchlaufen Sie jeden Eintrag im DataFrame und wenden Sie das Modell an\n",
    "for index, row in df.iterrows():\n",
    "    text = row['text']\n",
    "    text = preprocess(text)  # Stellen Sie sicher, dass Sie Ihre Preprocessing-Funktion hier verwenden\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    softmax_scores = softmax(scores)\n",
    "\n",
    "    # Extrahieren Sie das vorhergesagte Sentiment\n",
    "    predicted_label_id = np.argmax(softmax_scores)\n",
    "    #predicted_sentiment = model.config.id2label[predicted_label_id]\n",
    "\n",
    "    # Speichern Sie das vorhergesagte Sentiment und das tatsächliche Label\n",
    "    predicted_sentiments.append(predicted_label_id)\n",
    "    actual_labels.append(row['label'])\n",
    "\n",
    "# Fügen Sie die vorhergesagten Sentiments und die tatsächlichen Labels als neue Spalten zum DataFrame hinzu\n",
    "df['predicted_sentiment'] = predicted_sentiments\n",
    "\n",
    "# Vergleichen Sie die vorhergesagten Sentiments mit den tatsächlichen Labels\n",
    "correct_predictions = (df['predicted_sentiment'] == df['label']).sum()\n",
    "total_predictions = len(df)\n",
    "\n",
    "# Berechnen Sie die Genauigkeit (Accuracy) der Vorhersagen\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "# Drucken Sie die Genauigkeit\n",
    "print(f\"Genauigkeit: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test The Model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rb/6r0tm6px2yg64kgqwlg_q0800000gn/T/ipykernel_20813/3804968078.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Stellen Sie sicher, dass Sie Ihre Preprocessing-Funktion hier verwenden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mencoded_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# Laden Sie Ihren CSV-Datensatz\n",
    "csv_file = \"../../data/test_data.csv\"  # Ersetzen Sie durch den Pfad zu Ihrer CSV-Datei\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Leere Listen zum Speichern der vorhergesagten Sentiments und der tatsächlichen Labels\n",
    "predicted_sentiments = []\n",
    "actual_labels = []\n",
    "\n",
    "# Durchlaufen Sie jeden Eintrag im DataFrame und wenden Sie das Modell an\n",
    "for index, row in df.iterrows():\n",
    "    text = row['text']\n",
    "    text = preprocess(text)  # Stellen Sie sicher, dass Sie Ihre Preprocessing-Funktion hier verwenden\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    softmax_scores = softmax(scores)\n",
    "\n",
    "    # Extrahieren Sie das vorhergesagte Sentiment\n",
    "    predicted_label_id = np.argmax(softmax_scores)\n",
    "    #predicted_sentiment = model.config.id2label[predicted_label_id]\n",
    "\n",
    "    # Speichern Sie das vorhergesagte Sentiment und das tatsächliche Label\n",
    "    predicted_sentiments.append(predicted_label_id)\n",
    "    actual_labels.append(row['label'])\n",
    "\n",
    "# Fügen Sie die vorhergesagten Sentiments und die tatsächlichen Labels als neue Spalten zum DataFrame hinzu\n",
    "df['predicted_sentiment'] = predicted_sentiments\n",
    "\n",
    "# Vergleichen Sie die vorhergesagten Sentiments mit den tatsächlichen Labels\n",
    "correct_predictions = (df['predicted_sentiment'] == df['label']).sum()\n",
    "total_predictions = len(df)\n",
    "\n",
    "# Berechnen Sie die Genauigkeit (Accuracy) der Vorhersagen\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "# Drucken Sie die Genauigkeit\n",
    "print(f\"Genauigkeit: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print out confusion matrix and statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verwirrungsmatrix:\n",
      "[[247  58   7]\n",
      " [120 644 105]\n",
      " [ 17 150 652]]\n",
      "Precision pro Klasse: [0.64322917 0.75586854 0.85340314]\n",
      "Recall pro Klasse: [0.79166667 0.7410817  0.7960928 ]\n",
      "Macro Precision: 0.75\n",
      "Macro Recall: 0.78\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "\n",
    "# Berechnen Sie die Verwirrungsmatrix\n",
    "conf_matrix = confusion_matrix(df['label'], df['predicted_sentiment'])\n",
    "\n",
    "# Drucken Sie die Verwirrungsmatrix\n",
    "print(\"Verwirrungsmatrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Berechnen Sie die Precision und den Recall für jede Klasse\n",
    "precision = precision_score(df['label'], df['predicted_sentiment'], average=None)\n",
    "recall = recall_score(df['label'], df['predicted_sentiment'], average=None)\n",
    "\n",
    "# Drucken Sie die Precision und den Recall für jede Klasse\n",
    "print(\"Precision pro Klasse:\", precision)\n",
    "print(\"Recall pro Klasse:\", recall)\n",
    "\n",
    "# Berechnen Sie den gewichteten Durchschnitt von Precision und Recall (Macro-Durchschnitt)\n",
    "macro_precision = precision_score(df['label'], df['predicted_sentiment'], average='macro')\n",
    "macro_recall = recall_score(df['label'], df['predicted_sentiment'], average='macro')\n",
    "\n",
    "# Drucken Sie den gewichteten Durchschnitt von Precision und Recall\n",
    "print(f\"Macro Precision: {macro_precision:.2f}\")\n",
    "print(f\"Macro Recall: {macro_recall:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe54a73c18050b6d50975a0cc591f481f480ecb39df2bfc4b76ac59282f6b0b9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
