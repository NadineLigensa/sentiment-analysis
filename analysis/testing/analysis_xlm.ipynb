{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/sulu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/sulu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model from the web and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-16 10:01:15.547088: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MODEL = f\"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "# PT\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "model.save_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to preprocess the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden Sie den Datensatz mit den Unicode-Namen der Emojis\n",
    "emoji_data = {}\n",
    "with open('../../data/emoji_dataset.csv', mode='r', encoding='utf-8') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        emoji_data[row[2]] = row[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ersetze_emojis(text):\n",
    "    for emoji, name in emoji_data.items():\n",
    "        text = text.replace(emoji, name)\n",
    "    # Entfernen Sie Leerzeichen am Anfang und am Ende des Texts\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess text (username and link placeholders)\n",
    "def preprocess(text):\n",
    "\n",
    "    # emojis entfernen\n",
    "    #text = ersetze_emojis(text)\n",
    "\n",
    "    # lemmatizer = WordNetLemmatizer()\n",
    "    # words = text.split()\n",
    "    # lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    # text = ' '.join(lemmatized_words)\n",
    "\n",
    "\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good night üòä'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = preprocess(\"Good night üòä\")\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) positive 0.6129\n",
      "2) neutral 0.267\n",
      "3) negative 0.1202\n"
     ]
    }
   ],
   "source": [
    "text = \"Good night\"\n",
    "text = preprocess(text)\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "\n",
    "\n",
    "# Print labels and scores\n",
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "for i in range(scores.shape[0]):\n",
    "    l = config.id2label[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genauigkeit: 74.05%\n"
     ]
    }
   ],
   "source": [
    "# Laden Sie Ihren CSV-Datensatz\n",
    "csv_file = \"../../data/val_data.csv\"  # Ersetzen Sie durch den Pfad zu Ihrer CSV-Datei\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Leere Listen zum Speichern der vorhergesagten Sentiments und der tats√§chlichen Labels\n",
    "predicted_sentiments = []\n",
    "actual_labels = []\n",
    "\n",
    "count = 0\n",
    "# Durchlaufen Sie jeden Eintrag im DataFrame und wenden Sie das Modell an\n",
    "for index, row in df.iterrows():\n",
    "    text = row['text']\n",
    "    text = preprocess(text)  # Stellen Sie sicher, dass Sie Ihre Preprocessing-Funktion hier verwenden\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    softmax_scores = softmax(scores)\n",
    "\n",
    "    # Extrahieren Sie das vorhergesagte Sentiment\n",
    "    predicted_label_id = np.argmax(softmax_scores)\n",
    "    #predicted_sentiment = model.config.id2label[predicted_label_id]\n",
    "\n",
    "    # Speichern Sie das vorhergesagte Sentiment und das tats√§chliche Label\n",
    "    predicted_sentiments.append(predicted_label_id)\n",
    "    actual_labels.append(row['label'])\n",
    "\n",
    "# F√ºgen Sie die vorhergesagten Sentiments und die tats√§chlichen Labels als neue Spalten zum DataFrame hinzu\n",
    "df['predicted_sentiment'] = predicted_sentiments\n",
    "\n",
    "# Vergleichen Sie die vorhergesagten Sentiments mit den tats√§chlichen Labels\n",
    "correct_predictions = (df['predicted_sentiment'] == df['label']).sum()\n",
    "total_predictions = len(df)\n",
    "\n",
    "# Berechnen Sie die Genauigkeit (Accuracy) der Vorhersagen\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "# Drucken Sie die Genauigkeit\n",
    "print(f\"Genauigkeit: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genauigkeit: 67.28%\n"
     ]
    }
   ],
   "source": [
    "# Laden Sie Ihren CSV-Datensatz\n",
    "csv_file = \"../../data/test_data.csv\"  # Ersetzen Sie durch den Pfad zu Ihrer CSV-Datei\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Leere Listen zum Speichern der vorhergesagten Sentiments und der tats√§chlichen Labels\n",
    "predicted_sentiments = []\n",
    "actual_labels = []\n",
    "\n",
    "# Durchlaufen Sie jeden Eintrag im DataFrame und wenden Sie das Modell an\n",
    "for index, row in df.iterrows():\n",
    "    text = row['text']\n",
    "    #text = preprocess(text)  # Stellen Sie sicher, dass Sie Ihre Preprocessing-Funktion hier verwenden\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    softmax_scores = softmax(scores)\n",
    "\n",
    "    # Extrahieren Sie das vorhergesagte Sentiment\n",
    "    predicted_label_id = np.argmax(softmax_scores)\n",
    "    #predicted_sentiment = model.config.id2label[predicted_label_id]\n",
    "\n",
    "    # Speichern Sie das vorhergesagte Sentiment und das tats√§chliche Label\n",
    "    predicted_sentiments.append(predicted_label_id)\n",
    "    actual_labels.append(row['label'])\n",
    "\n",
    "# F√ºgen Sie die vorhergesagten Sentiments und die tats√§chlichen Labels als neue Spalten zum DataFrame hinzu\n",
    "df['predicted_sentiment'] = predicted_sentiments\n",
    "\n",
    "# Vergleichen Sie die vorhergesagten Sentiments mit den tats√§chlichen Labels\n",
    "correct_predictions = (df['predicted_sentiment'] == df['label']).sum()\n",
    "total_predictions = len(df)\n",
    "\n",
    "# Berechnen Sie die Genauigkeit (Accuracy) der Vorhersagen\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "# Drucken Sie die Genauigkeit\n",
    "print(f\"Genauigkeit: {accuracy:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe54a73c18050b6d50975a0cc591f481f480ecb39df2bfc4b76ac59282f6b0b9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
